{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Manipulation\n",
    "\n",
    "Update: May 23, 2024\n",
    "\n",
    "Author: Languisher Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Attrubutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " tensor([[2, 3, 4, 5, 6],\n",
       "         [1, 2, 3, 4, 5]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Tensor attributes and characteristics --- ###\n",
    "\n",
    "# Creating tensors prepopulated with values\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "xx = torch.tensor([[2, 3, 4, 5, 6], [1, 2, 3, 4, 5]])\n",
    "\n",
    "x, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, torch.Size([2, 5]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of elements of the tensor\n",
    "num_elements = x.numel()\n",
    "\n",
    "# Shape of tensor, first number correspond to the outer layer of the list, \n",
    "# (in this case, the number of elements of each column)\n",
    "xx_shape = xx.shape\n",
    "\n",
    "num_elements, xx_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the shape without altering its size of values\n",
    "# e.g. (12, ) -> (3, 4)\n",
    "X = x.reshape(3, 4)\n",
    "\n",
    "# To automatically infer ONE COMPONENT of the shape\n",
    "# (obviously it could be at least inferred manually)\n",
    "Y = x.reshape(-1, 4)\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]),\n",
       " tensor([[ 0.7742, -0.8226, -0.0597,  1.4078],\n",
       "         [-0.8552,  0.1352, -0.8441,  0.6571],\n",
       "         [-1.4065, -0.5721, -0.1290, -2.4971]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors with all 0s or 1s\n",
    "zero_tensor = torch.zeros((2, 3, 4))\n",
    "one_tensor = torch.ones((2, 5))\n",
    "\n",
    "# Create tensor with random values drawn from \n",
    "# a std Gaussian (normal) distrubution with mean 0 and deviation 1\n",
    "normal_tensor = torch.randn((3, 4))\n",
    "\n",
    "zero_tensor, one_tensor, normal_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[12., 12., 12., 12.],\n",
       "         [12., 12., 12., 12.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing: Similar to list\n",
    "\n",
    "# Output the values of the tesnor\n",
    "last_line = X[-1]\n",
    "last_two_lines = X[1:3] # 1 and 2 but 3 is not contained\n",
    "\n",
    "# Assign single elements and multiple elements with the same value\n",
    "Y = X.clone() # Clone to \"deepcopy\"\n",
    "Y[1, 2] = 17 \n",
    "Y[:2, :] = 12\n",
    "\n",
    "X, last_line, last_two_lines, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
       "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04]),\n",
       " tensor([ 8, 81]),\n",
       " tensor([False, False]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unary Operations: Functions operate like: f: R^p -> R^n\n",
    "exp_x = torch.exp(x)\n",
    "\n",
    "# Binary Operations: Between tensors\n",
    "a = torch.tensor([2, 3])\n",
    "b = torch.tensor([3, 4])\n",
    "atimesb = a ** b\n",
    "\n",
    "# Test for every element if equal or not\n",
    "aequalb = a == b\n",
    "\n",
    "x, exp_x, atimesb, aequalb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenation multiple tensors\n",
    "# Concate two matrices along rows: axis 0\n",
    "# Concate two matrices along columns: axis 1\n",
    "\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "row_concate = torch.cat((X, Y), dim=0)\n",
    "col_concate = torch.cat((X, Y), dim=1)\n",
    "\n",
    "row_concate, col_concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]),\n",
       " tensor([[0, 1],\n",
       "         [1, 2],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "\n",
    "# In order to make the shape of a and b becomes identical, broadcasting\n",
    "# is adopted. That is to say, (3, 1) -> (3, 2) by coping the column\n",
    "# (1, 2) -> (3, 2) by coping two times the line\n",
    "\n",
    "a, b, a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memory saving\n",
    "# Take this as an example: We want to update the value of a certain tensor,\n",
    "# without allocating a num memory but only covering (or replacing) the original\n",
    "# data\n",
    "\n",
    "Z = torch.zeros((3, 4))\n",
    "id_orig = id(Z)\n",
    "\n",
    "X = Y = torch.ones((3, 4))\n",
    "Z[:] = X + Y # By adding a \"[:]\", we could avoid allocating new memory spaces\n",
    "id_new = id(Z)\n",
    "\n",
    "id_orig == id_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to other Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "\n",
    "# Torch -> Numpy: numpy method\n",
    "# Numpy -> Torch: from_numpy method\n",
    "# Attention: Two use cases are DIFFERENT !!!\n",
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [2.1 Data Manipulation](https://d2l.ai/chapter_preliminaries/ndarray.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
