{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Manipulation and Preprocessing\n",
    "\n",
    "Update: May 23, 2024\n",
    "\n",
    "Author: Languisher Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Attrubutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " tensor([[2, 3, 4, 5, 6],\n",
       "         [1, 2, 3, 4, 5]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Tensor attributes and characteristics --- ###\n",
    "\n",
    "# Creating tensors prepopulated with values\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "xx = torch.tensor([[2, 3, 4, 5, 6], [1, 2, 3, 4, 5]])\n",
    "\n",
    "x, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, torch.Size([2, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of elements of the tensor\n",
    "num_elements = x.numel()\n",
    "\n",
    "# Shape of tensor, first number correspond to the outer layer of the list, \n",
    "# (in this case, the number of elements of each column)\n",
    "xx_shape = xx.shape\n",
    "\n",
    "num_elements, xx_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the shape without altering its size of values\n",
    "# e.g. (12, ) -> (3, 4)\n",
    "X = x.reshape(3, 4)\n",
    "\n",
    "# To automatically infer ONE COMPONENT of the shape\n",
    "# (obviously it could be at least inferred manually)\n",
    "Y = x.reshape(-1, 4)\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]),\n",
       " tensor([[-1.1151,  0.2723,  0.7684,  0.8018],\n",
       "         [ 1.1924, -2.4827, -0.0274, -0.1840],\n",
       "         [-0.5955, -0.4199,  0.1617,  0.9762]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors with all 0s or 1s\n",
    "zero_tensor = torch.zeros((2, 3, 4))\n",
    "one_tensor = torch.ones((2, 5))\n",
    "\n",
    "# Create tensor with random values drawn from \n",
    "# a std Gaussian (normal) distrubution with mean 0 and deviation 1\n",
    "normal_tensor = torch.randn((3, 4))\n",
    "\n",
    "zero_tensor, one_tensor, normal_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[12., 12., 12., 12.],\n",
       "         [12., 12., 12., 12.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing: Similar to list\n",
    "\n",
    "# Output the values of the tesnor\n",
    "last_line = X[-1]\n",
    "last_two_lines = X[1:3] # 1 and 2 but 3 is not contained\n",
    "\n",
    "# Assign single elements and multiple elements with the same value\n",
    "Y = X.clone() # Clone to \"deepcopy\"\n",
    "Y[1, 2] = 17 \n",
    "Y[:2, :] = 12\n",
    "\n",
    "X, last_line, last_two_lines, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]),\n",
       " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
       "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04]),\n",
       " tensor([ 8, 81]),\n",
       " tensor([False, False]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unary Operations: Functions operate like: f: R^p -> R^n\n",
    "exp_x = torch.exp(x)\n",
    "\n",
    "# Binary Operations: Between tensors\n",
    "a = torch.tensor([2, 3])\n",
    "b = torch.tensor([3, 4])\n",
    "atimesb = a ** b\n",
    "\n",
    "# Test for every element if equal or not\n",
    "aequalb = a == b\n",
    "\n",
    "x, exp_x, atimesb, aequalb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenation multiple tensors\n",
    "# Concate two matrices along rows: axis 0\n",
    "# Concate two matrices along columns: axis 1\n",
    "\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "row_concate = torch.cat((X, Y), dim=0)\n",
    "col_concate = torch.cat((X, Y), dim=1)\n",
    "\n",
    "row_concate, col_concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]),\n",
       " tensor([[0, 1],\n",
       "         [1, 2],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting\n",
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "\n",
    "# In order to make the shape of a and b becomes identical, broadcasting\n",
    "# is adopted. That is to say, (3, 1) -> (3, 2) by coping the column\n",
    "# (1, 2) -> (3, 2) by coping two times the line\n",
    "\n",
    "a, b, a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memory saving\n",
    "# Take this as an example: We want to update the value of a certain tensor,\n",
    "# without allocating a num memory but only covering (or replacing) the original\n",
    "# data\n",
    "\n",
    "Z = torch.zeros((3, 4))\n",
    "id_orig = id(Z)\n",
    "\n",
    "X = Y = torch.ones((3, 4))\n",
    "Z[:] = X + Y # By adding a \"[:]\", we could avoid allocating new memory spaces\n",
    "id_new = id(Z)\n",
    "\n",
    "id_orig == id_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to other Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "\n",
    "# Torch -> Numpy: numpy method\n",
    "# Numpy -> Torch: from_numpy method\n",
    "# Attention: Two use cases are DIFFERENT !!!\n",
    "A = X.numpy()\n",
    "B = torch.from_numpy(A)\n",
    "\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "\n",
    "Second-order tensors could be expressed as, mathematically, matrices.\n",
    "\n",
    "$$\n",
    "\\mathrm{A} = \\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & & \\vdots \\\\ a_{m1} & \\cdots & a_{mn}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 2, 4],\n",
       "         [1, 3, 5]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2) # 3 is the number of lines, thus m=3 and (m, n) = (3, 2)\n",
    "A, A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadamard product: denote $c_{ij}$ as the element of the result matrix,\n",
    "$$\n",
    "\\forall i, j \\in [\\![1, m]\\!] \\times [\\![1, n]\\!],\\quad c_{ij} = a_{ij} \\times b_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[ 0,  1],\n",
       "         [ 4,  9],\n",
       "         [16, 25]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.clone()\n",
    "A, A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product (Inner product): $$ \\langle x, y \\rangle = \\mathrm{x}^T \\mathrm{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input should be R^d VECTORS !!!!\n",
    "# Both should be COLUMN VECTORS !!!\n",
    "x = torch.ones(3, dtype=torch.float32)\n",
    "y = torch.ones(3, dtype=torch.float32)\n",
    "\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-Vector (MV) Products, Matrix-Matrix(MM) Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3., 12.]),\n",
       " tensor([ 3., 12.]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the shape of the matrices and vectors first.\n",
    "\n",
    "A = torch.arange(6, dtype=torch.float32).reshape((2, 3))\n",
    "B = torch.ones((3, 4))\n",
    "v = torch.ones(3)\n",
    "\n",
    "# mv denotes matrix-vector, mm denotes matrix-matrix\n",
    "A@v, torch.mv(A, v), A@B, torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum (Reduction or Non-Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor(15.),\n",
       " tensor([3., 5., 7.]),\n",
       " tensor([ 3., 12.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of all elements\n",
    "total_sum = A.sum()\n",
    "\n",
    "# Sum over all elements ALONG THE ROW, i.e. sum of each column: axis=0\n",
    "# Sum over all elements ALONG THE COLUMN, i.e. sum of each row: axis=1\n",
    "col_sum = A.sum(axis=0)\n",
    "line_sum = A.sum(axis=1)\n",
    "\n",
    "\n",
    "A, total_sum, col_sum, line_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norm: $l_2$ norm and Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method norm calculates the l_2 norm and Frobenius Norm\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "X = torch.ones((4, 9))\n",
    "\n",
    "torch.norm(u), torch.norm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>RoofType</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Slate</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms RoofType   Price\n",
       "0       NaN      NaN  127500\n",
       "1       2.0      NaN  106000\n",
       "2       4.0    Slate  178100\n",
       "3       NaN      NaN  140000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should deal with the problem of \"NaN\" datas. O\n",
    "One simple way is to convert these values into 0 and 1 bits, or to take the mean value of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>RoofType_Slate</th>\n",
       "      <th>RoofType_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms  RoofType_Slate  RoofType_nan\n",
       "0       3.0           False          True\n",
       "1       2.0           False          True\n",
       "2       4.0            True         False\n",
       "3       3.0           False          True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, target = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True) # Convert into two columns\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we could convert it to a tensor using the techniques we have already discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Route of convert:\n",
    "# Panda Column -> Numpy -> Torch\n",
    "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "y = torch.tensor(target.to_numpy(dtype=float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [2.1 Data Manipulation](https://d2l.ai/chapter_preliminaries/ndarray.html)\n",
    "- [2.2 Data Preprocessing](https://d2l.ai/chapter_preliminaries/pandas.html#)\n",
    "- [2.3 Linear Algebra](https://d2l.ai/chapter_preliminaries/linear-algebra.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
